{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state transition bias and reward function for a cart pole system\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdim = 4\n",
    "adim = 1\n",
    "ssize = 10\n",
    "asize = 100\n",
    "srange = np.array([-np.pi/4, np.pi/4, -3, 3, -2.4, 2.4, -3.5, 3.5])\n",
    "arange = np.array([-10, 10])\n",
    "\n",
    "g = 9.8\n",
    "l =0.5\n",
    "M = 1\n",
    "m = 0.1\n",
    "tau = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(c, d):\n",
    "    return [list(np.ndindex(*d))[i] for i in c]\n",
    "\n",
    "\n",
    "def foldParallel(c, d):\n",
    "    p = np.array([np.prod(d[i + 1 :]) for i, _ in enumerate(d)])\n",
    "    return np.sum(c * p, -1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_spaces(srange, arange, ssize, asize, sdim, adim):\n",
    "    srange = np.reshape(srange, (sdim, -1))\n",
    "    arange = np.reshape(arange, (adim, -1))\n",
    "\n",
    "    # Dicretization of [a, b] will include a, but exlude b when range if not multiple of step-size\n",
    "    statespace = np.meshgrid(*[np.linspace(a, b, ssize) for (a, b) in srange])\n",
    "    actionspace = np.meshgrid(*[np.linspace(a, b, asize) for (a, b) in arange])\n",
    "\n",
    "    return statespace, actionspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "statespace, actionspace = build_spaces(srange, arange, ssize, asize, sdim, adim)\n",
    "# print(statespace)\n",
    "# cs = np.random.randint(0, statespace[0].size, samples) # current states\n",
    "# ca = np.random.randint(0, actionspace[0].size, samples) # current states\n",
    "\n",
    "# states = np.array(unfold(cs, statespace[0].shape))\n",
    "# states = np.array([s[states] for s in statespace])\n",
    "# actions = np.array(unfold(ca, actionspace[0].shape))\n",
    "# states = np.array([a[actions] for a in actionspace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_action_bias_reward(statespace, actionspace, args):\n",
    "    \"\"\"\n",
    "    nstates: total number of states\n",
    "    nactions: total number of actions\n",
    "    \"\"\"\n",
    "    assert len(srange.shape) == 1\n",
    "    #assert args.adim == 1\n",
    "    \n",
    "    coords = np.array(statespace).reshape(sdim, -1).transpose()\n",
    "    coorda = actionspace[0]\n",
    "    c = np.array(list(np.ndindex(len(coords), len(coorda))))\n",
    "    cartcoord = np.c_[coords[c[:, 0]], coorda[c[:, 1]]]\n",
    "    \n",
    "    angaccel = (g * np.sin(cartcoord[:,0]) - (cartcoord[:, -1] + m * l * cartcoord[:,1] ** 2 * np.sin(cartcoord[:,0])) * np.cos(cartcoord[:,0]) / (M + m)) / (l * (4 / 3 - (m * np.cos(cartcoord[:,0]) ** 2) / (M+m)))\n",
    "    linaccel = (cartcoord[:, -1] + m * l *(cartcoord[:,0] ** 2 * np.sin(cartcoord[:,0]) - angaccel * np.cos(cartcoord[:,0]))) / (M + m)\n",
    "    \n",
    "    bias = np.c_[tau*cartcoord[:,1], tau*angaccel, tau*cartcoord[:,2], tau*linaccel]\n",
    "    \n",
    "    reward = np.reshape(np.cos(cartcoord[:, 0]) ** 4, (len(coords), len(coorda), -1))\n",
    "    \n",
    "    # convert to discrete co-ordinates\n",
    "    statesrange = np.reshape(srange, (sdim, -1))\n",
    "    sr = np.array([np.linspace(a, b, ssize) for (a, b) in statesrange]) #use args.ssize\n",
    "    bias = np.array(\n",
    "        [\n",
    "            np.argmin(np.abs(bias[:, i : i + 1] - sr[i : i + 1]), -1)\n",
    "            for i in range(sdim)\n",
    "        ]\n",
    "    ).T\n",
    "    bias = np.reshape(bias, (len(coords), len(coorda), -1))\n",
    "    return bias, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, R = get_state_action_bias_reward(statespace, actionspace, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-31836aeaab22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.45025452, 0.67468778, 0.8705127 , 0.98486545])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853981633974483"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "momentum tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sdim = 3\n",
    "params = torch.ones(2, sdim)\n",
    "print(\"params\", params)\n",
    "\n",
    "momentum = torch.ones(2, sdim)\n",
    "print(\"momentum\",momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.zeros(1, sdim), torch.ones(1, sdim)], dim =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(omega, c=None, mean=None, stddev=None, srange=None):\n",
    "    \"\"\"\n",
    "        Sampling from a trucated Gaussian distribution\n",
    "        mean: shape-(N, sdim)\n",
    "        cov: shape-(sdim, sdim), assuming identical convariance for all samples\n",
    "    \"\"\"\n",
    "\n",
    "    cov = stddev ** 2\n",
    "    normal_log = torch.distributions.MultivariateNormal(mean, cov).log_prob(omega)\n",
    "    \n",
    "    if c:\n",
    "        s = torch.nn.functional.logsigmoid(c * (omega - srange[:, 0].view(1, -1))).sum(-1) + torch.nn.functional.logsigmoid(c * (srange[:, 1].view(1, -1) - omega)).sum(-1)\n",
    "        return normal_log + s\n",
    "    else:\n",
    "        return normal_log\n",
    "    \n",
    "\n",
    "def getlogprobs(c, mean, stddev, srange):\n",
    "    \"\"\"\n",
    "        Wrapper for passing parameters of trucated Gaussian distribution\n",
    "    \"\"\"\n",
    "\n",
    "    def f(omega):\n",
    "        return log_prob(omega, c, mean, stddev, srange)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001505136489868164\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "samples = 100000\n",
    "omega = torch.ones(samples, sdim)\n",
    "\n",
    "mean = torch.zeros(samples, sdim)\n",
    "cov = torch.eye(sdim)\n",
    "\n",
    "start = time.time()\n",
    "normal_log = torch.distributions.MultivariateNormal(mean, cov).log_prob(omega)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5404,  0.4478, -0.8836],\n",
      "        [ 0.5951,  0.8123,  1.5449]])\n"
     ]
    }
   ],
   "source": [
    "def gibbs(\n",
    "    params,\n",
    "    mass=None,\n",
    "):\n",
    "\n",
    "    if mass is None:\n",
    "        dist = torch.distributions.Normal(\n",
    "            torch.zeros_like(params), torch.ones_like(params)\n",
    "        )\n",
    "    else:\n",
    "        if len(mass.shape) == 2:\n",
    "            dist = torch.distributions.MultivariateNormal(\n",
    "                torch.zeros_like(params), mass\n",
    "            )\n",
    "        elif len(mass.shape) == 1:\n",
    "            dist = torch.distributions.Normal(torch.zeros_like(params), mass)\n",
    "    return dist.sample()\n",
    "\n",
    "print(gibbs(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.7568, 5.2965])\n"
     ]
    }
   ],
   "source": [
    "def hamiltonian(\n",
    "    params,\n",
    "    momentum,\n",
    "    log_prob_func,\n",
    "    inv_mass=None,\n",
    "):\n",
    "\n",
    "    log_prob = log_prob_func(params)\n",
    "    potential = -log_prob\n",
    "    \n",
    "    if inv_mass is None:\n",
    "        kinetic = 0.5 * torch.sum(momentum ** 2, dim = -1)\n",
    "        \n",
    "    else:\n",
    "        if len(inv_mass.shape) == 2:\n",
    "            # Have not checked for parallel\n",
    "            kinetic = 0.5 * torch.matmul(\n",
    "                momentum.view(1, -1), torch.matmul(inv_mass, momentum.view(-1, 1))\n",
    "            ).view(-1)\n",
    "        else:\n",
    "            kinetic = 0.5 * inv_mass * torch.sum(momentum ** 2, dim = -1)\n",
    "    hamiltonian = potential + kinetic\n",
    "\n",
    "    return hamiltonian\n",
    "\n",
    "print(hamiltonian(params, momentum, log_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 3],[2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor([2, 3]) **2 ,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.tensor([2, 3]),torch.tensor([2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_gradients(log_prob, params):\n",
    "    params.grad = torch.autograd.grad(log_prob.sum(), params)[0]\n",
    "    return params\n",
    "\n",
    "\n",
    "def leapfrog(\n",
    "    params,\n",
    "    momentum,\n",
    "    log_prob_func,\n",
    "    steps=10,\n",
    "    step_size=0.1,\n",
    "    inv_mass=None,\n",
    "):\n",
    "    # params: shape (N, sdim)\n",
    "\n",
    "    def params_grad(p):\n",
    "        p = p.detach().requires_grad_()\n",
    "        log_prob = log_prob_func(p)\n",
    "        p = collect_gradients(log_prob, p)\n",
    "        return p.grad\n",
    "\n",
    "    ret_params = []\n",
    "    ret_momenta = []\n",
    "    momentum += 0.5 * step_size * params_grad(params)\n",
    "    print(\"m\", momentum.shape)\n",
    "    for n in range(steps):\n",
    "        if inv_mass is None:\n",
    "            params = params + step_size * momentum\n",
    "        else:\n",
    "            # Assum G is diag here so 1/Mass = G inverse\n",
    "            if len(inv_mass.shape) == 2:\n",
    "                params = params + step_size * torch.matmul(\n",
    "                    inv_mass, momentum.view(-1, 1)\n",
    "                ).view(-1)\n",
    "            else:\n",
    "                params = params + step_size * inv_mass * momentum\n",
    "        p_grad = params_grad(params)\n",
    "        momentum += step_size * p_grad\n",
    "        ret_params.append(params.clone())\n",
    "        ret_momenta.append(momentum.clone())\n",
    "    # only need last for Hamiltoninian check (see p.14) https://arxiv.org/pdf/1206.1901.pdf\n",
    "    ret_momenta[-1] = ret_momenta[-1] - 0.5 * step_size * p_grad.clone()\n",
    "    # import pdb; pdb.set_trace()\n",
    "    return ret_params, ret_momenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.ones([10, 3])\n",
    "m = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "a, b = leapfrog(p, m, getlogprobs(100, torch.zeros(10, 3), torch.eye(3), torch.tensor([[-1., 1.], [-1., 1.], [-1., 1.]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450]]), tensor([[0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825]]), tensor([[0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153]]), tensor([[-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542]]), tensor([[-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230]]), tensor([[-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887]]), tensor([[-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485]]), tensor([[-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998]]), tensor([[-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401]]), tensor([[0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230]])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245]]), tensor([[-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728]]), tensor([[-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943]]), tensor([[-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889]]), tensor([[-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566]]), tensor([[-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977]]), tensor([[-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128]]), tensor([[7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967]]), tensor([[7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307]]), tensor([[7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095]])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
