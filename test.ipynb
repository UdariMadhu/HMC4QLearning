{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T01:34:38.866031Z",
     "start_time": "2020-09-19T01:34:38.420896Z"
    }
   },
   "outputs": [],
   "source": [
    "# state transition bias and reward function for a cart pole system\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdim = 4\n",
    "adim = 1\n",
    "ssize = 10\n",
    "asize = 100\n",
    "srange = np.array([-np.pi/4, np.pi/4, -3, 3, -2.4, 2.4, -3.5, 3.5])\n",
    "arange = np.array([-10, 10])\n",
    "\n",
    "g = 9.8\n",
    "l =0.5\n",
    "M = 1\n",
    "m = 0.1\n",
    "tau = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(c, d):\n",
    "    return [list(np.ndindex(*d))[i] for i in c]\n",
    "\n",
    "\n",
    "def foldParallel(c, d):\n",
    "    p = np.array([np.prod(d[i + 1 :]) for i, _ in enumerate(d)])\n",
    "    return np.sum(c * p, -1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_spaces(srange, arange, ssize, asize, sdim, adim):\n",
    "    srange = np.reshape(srange, (sdim, -1))\n",
    "    arange = np.reshape(arange, (adim, -1))\n",
    "\n",
    "    # Dicretization of [a, b] will include a, but exlude b when range if not multiple of step-size\n",
    "    statespace = np.meshgrid(*[np.linspace(a, b, ssize) for (a, b) in srange])\n",
    "    actionspace = np.meshgrid(*[np.linspace(a, b, asize) for (a, b) in arange])\n",
    "\n",
    "    return statespace, actionspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "statespace, actionspace = build_spaces(srange, arange, ssize, asize, sdim, adim)\n",
    "# print(statespace)\n",
    "# cs = np.random.randint(0, statespace[0].size, samples) # current states\n",
    "# ca = np.random.randint(0, actionspace[0].size, samples) # current states\n",
    "\n",
    "# states = np.array(unfold(cs, statespace[0].shape))\n",
    "# states = np.array([s[states] for s in statespace])\n",
    "# actions = np.array(unfold(ca, actionspace[0].shape))\n",
    "# states = np.array([a[actions] for a in actionspace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_action_bias_reward(statespace, actionspace, args):\n",
    "    \"\"\"\n",
    "    nstates: total number of states\n",
    "    nactions: total number of actions\n",
    "    \"\"\"\n",
    "    assert len(srange.shape) == 1\n",
    "    #assert args.adim == 1\n",
    "    \n",
    "    coords = np.array(statespace).reshape(sdim, -1).transpose()\n",
    "    coorda = actionspace[0]\n",
    "    c = np.array(list(np.ndindex(len(coords), len(coorda))))\n",
    "    cartcoord = np.c_[coords[c[:, 0]], coorda[c[:, 1]]]\n",
    "    \n",
    "    angaccel = (g * np.sin(cartcoord[:,0]) - (cartcoord[:, -1] + m * l * cartcoord[:,1] ** 2 * np.sin(cartcoord[:,0])) * np.cos(cartcoord[:,0]) / (M + m)) / (l * (4 / 3 - (m * np.cos(cartcoord[:,0]) ** 2) / (M+m)))\n",
    "    linaccel = (cartcoord[:, -1] + m * l *(cartcoord[:,0] ** 2 * np.sin(cartcoord[:,0]) - angaccel * np.cos(cartcoord[:,0]))) / (M + m)\n",
    "    \n",
    "    bias = np.c_[tau*cartcoord[:,1], tau*angaccel, tau*cartcoord[:,2], tau*linaccel]\n",
    "    \n",
    "    reward = np.reshape(np.cos(cartcoord[:, 0]) ** 4, (len(coords), len(coorda), -1))\n",
    "    \n",
    "    # convert to discrete co-ordinates\n",
    "    statesrange = np.reshape(srange, (sdim, -1))\n",
    "    sr = np.array([np.linspace(a, b, ssize) for (a, b) in statesrange]) #use args.ssize\n",
    "    bias = np.array(\n",
    "        [\n",
    "            np.argmin(np.abs(bias[:, i : i + 1] - sr[i : i + 1]), -1)\n",
    "            for i in range(sdim)\n",
    "        ]\n",
    "    ).T\n",
    "    bias = np.reshape(bias, (len(coords), len(coorda), -1))\n",
    "    return bias, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, R = get_state_action_bias_reward(statespace, actionspace, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-31836aeaab22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.45025452, 0.67468778, 0.8705127 , 0.98486545])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853981633974483"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "momentum tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sdim = 3\n",
    "params = torch.ones(2, sdim)\n",
    "print(\"params\", params)\n",
    "\n",
    "momentum = torch.ones(2, sdim)\n",
    "print(\"momentum\",momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.zeros(1, sdim), torch.ones(1, sdim)], dim =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(omega, c=None, mean=None, stddev=None, srange=None):\n",
    "    \"\"\"\n",
    "        Sampling from a trucated Gaussian distribution\n",
    "        mean: shape-(N, sdim)\n",
    "        cov: shape-(sdim, sdim), assuming identical convariance for all samples\n",
    "    \"\"\"\n",
    "\n",
    "    cov = stddev ** 2\n",
    "    normal_log = torch.distributions.MultivariateNormal(mean, cov).log_prob(omega)\n",
    "    \n",
    "    if c:\n",
    "        s = torch.nn.functional.logsigmoid(c * (omega - srange[:, 0].view(1, -1))).sum(-1) + torch.nn.functional.logsigmoid(c * (srange[:, 1].view(1, -1) - omega)).sum(-1)\n",
    "        return normal_log + s\n",
    "    else:\n",
    "        return normal_log\n",
    "    \n",
    "\n",
    "def getlogprobs(c, mean, stddev, srange):\n",
    "    \"\"\"\n",
    "        Wrapper for passing parameters of trucated Gaussian distribution\n",
    "    \"\"\"\n",
    "\n",
    "    def f(omega):\n",
    "        return log_prob(omega, c, mean, stddev, srange)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001505136489868164\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "samples = 100000\n",
    "omega = torch.ones(samples, sdim)\n",
    "\n",
    "mean = torch.zeros(samples, sdim)\n",
    "cov = torch.eye(sdim)\n",
    "\n",
    "start = time.time()\n",
    "normal_log = torch.distributions.MultivariateNormal(mean, cov).log_prob(omega)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5404,  0.4478, -0.8836],\n",
      "        [ 0.5951,  0.8123,  1.5449]])\n"
     ]
    }
   ],
   "source": [
    "def gibbs(\n",
    "    params,\n",
    "    mass=None,\n",
    "):\n",
    "\n",
    "    if mass is None:\n",
    "        dist = torch.distributions.Normal(\n",
    "            torch.zeros_like(params), torch.ones_like(params)\n",
    "        )\n",
    "    else:\n",
    "        if len(mass.shape) == 2:\n",
    "            dist = torch.distributions.MultivariateNormal(\n",
    "                torch.zeros_like(params), mass\n",
    "            )\n",
    "        elif len(mass.shape) == 1:\n",
    "            dist = torch.distributions.Normal(torch.zeros_like(params), mass)\n",
    "    return dist.sample()\n",
    "\n",
    "print(gibbs(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.7568, 5.2965])\n"
     ]
    }
   ],
   "source": [
    "def hamiltonian(\n",
    "    params,\n",
    "    momentum,\n",
    "    log_prob_func,\n",
    "    inv_mass=None,\n",
    "):\n",
    "\n",
    "    log_prob = log_prob_func(params)\n",
    "    potential = -log_prob\n",
    "    \n",
    "    if inv_mass is None:\n",
    "        kinetic = 0.5 * torch.sum(momentum ** 2, dim = -1)\n",
    "        \n",
    "    else:\n",
    "        if len(inv_mass.shape) == 2:\n",
    "            # Have not checked for parallel\n",
    "            kinetic = 0.5 * torch.matmul(\n",
    "                momentum.view(1, -1), torch.matmul(inv_mass, momentum.view(-1, 1))\n",
    "            ).view(-1)\n",
    "        else:\n",
    "            kinetic = 0.5 * inv_mass * torch.sum(momentum ** 2, dim = -1)\n",
    "    hamiltonian = potential + kinetic\n",
    "\n",
    "    return hamiltonian\n",
    "\n",
    "print(hamiltonian(params, momentum, log_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 3],[2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor([2, 3]) **2 ,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.tensor([2, 3]),torch.tensor([2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_gradients(log_prob, params):\n",
    "    params.grad = torch.autograd.grad(log_prob.sum(), params)[0]\n",
    "    return params\n",
    "\n",
    "\n",
    "def leapfrog(\n",
    "    params,\n",
    "    momentum,\n",
    "    log_prob_func,\n",
    "    steps=10,\n",
    "    step_size=0.1,\n",
    "    inv_mass=None,\n",
    "):\n",
    "    # params: shape (N, sdim)\n",
    "\n",
    "    def params_grad(p):\n",
    "        p = p.detach().requires_grad_()\n",
    "        log_prob = log_prob_func(p)\n",
    "        p = collect_gradients(log_prob, p)\n",
    "        return p.grad\n",
    "\n",
    "    ret_params = []\n",
    "    ret_momenta = []\n",
    "    momentum += 0.5 * step_size * params_grad(params)\n",
    "    print(\"m\", momentum.shape)\n",
    "    for n in range(steps):\n",
    "        if inv_mass is None:\n",
    "            params = params + step_size * momentum\n",
    "        else:\n",
    "            # Assum G is diag here so 1/Mass = G inverse\n",
    "            if len(inv_mass.shape) == 2:\n",
    "                params = params + step_size * torch.matmul(\n",
    "                    inv_mass, momentum.view(-1, 1)\n",
    "                ).view(-1)\n",
    "            else:\n",
    "                params = params + step_size * inv_mass * momentum\n",
    "        p_grad = params_grad(params)\n",
    "        momentum += step_size * p_grad\n",
    "        ret_params.append(params.clone())\n",
    "        ret_momenta.append(momentum.clone())\n",
    "    # only need last for Hamiltoninian check (see p.14) https://arxiv.org/pdf/1206.1901.pdf\n",
    "    ret_momenta[-1] = ret_momenta[-1] - 0.5 * step_size * p_grad.clone()\n",
    "    # import pdb; pdb.set_trace()\n",
    "    return ret_params, ret_momenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.ones([10, 3])\n",
    "m = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "a, b = leapfrog(p, m, getlogprobs(100, torch.zeros(10, 3), torch.eye(3), torch.tensor([[-1., 1.], [-1., 1.], [-1., 1.]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450],\n",
       "         [0.7450, 0.7450, 0.7450]]), tensor([[0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825],\n",
       "         [0.4825, 0.4825, 0.4825]]), tensor([[0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153],\n",
       "         [0.2153, 0.2153, 0.2153]]), tensor([[-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542],\n",
       "         [-0.0542, -0.0542, -0.0542]]), tensor([[-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230],\n",
       "         [-0.3230, -0.3230, -0.3230]]), tensor([[-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887],\n",
       "         [-0.5887, -0.5887, -0.5887]]), tensor([[-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485],\n",
       "         [-0.8485, -0.8485, -0.8485]]), tensor([[-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998],\n",
       "         [-1.0998, -1.0998, -1.0998]]), tensor([[-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401],\n",
       "         [-0.3401, -0.3401, -0.3401]]), tensor([[0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230],\n",
       "         [0.4230, 0.4230, 0.4230]])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245],\n",
       "         [-2.6245, -2.6245, -2.6245]]), tensor([[-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728],\n",
       "         [-2.6728, -2.6728, -2.6728]]), tensor([[-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943],\n",
       "         [-2.6943, -2.6943, -2.6943]]), tensor([[-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889],\n",
       "         [-2.6889, -2.6889, -2.6889]]), tensor([[-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566],\n",
       "         [-2.6566, -2.6566, -2.6566]]), tensor([[-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977],\n",
       "         [-2.5977, -2.5977, -2.5977]]), tensor([[-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128],\n",
       "         [-2.5128, -2.5128, -2.5128]]), tensor([[7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967],\n",
       "         [7.5967, 7.5967, 7.5967]]), tensor([[7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307],\n",
       "         [7.6307, 7.6307, 7.6307]]), tensor([[7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095],\n",
       "         [7.6095, 7.6095, 7.6095]])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones([10, 10])\n",
    "mask = np.ones([10, 10]).astype(np.bool)\n",
    "\n",
    "index = np.random.randint(0, 10, [2, 50])\n",
    "X[index[0], index[1]] = np.random.randint(0, 10, index.shape[-1])\n",
    "mask[index[0], index[1]] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixEstimation import SoftImpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = SoftImpute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 27.066187\n",
      "[SoftImpute] Iter 1: observed MAE=0.213555 rank=10\n",
      "[SoftImpute] Iter 2: observed MAE=0.212877 rank=9\n",
      "[SoftImpute] Iter 3: observed MAE=0.210715 rank=9\n",
      "[SoftImpute] Iter 4: observed MAE=0.210591 rank=9\n",
      "[SoftImpute] Iter 5: observed MAE=0.210932 rank=9\n",
      "[SoftImpute] Iter 6: observed MAE=0.208878 rank=8\n",
      "[SoftImpute] Iter 7: observed MAE=0.205365 rank=8\n",
      "[SoftImpute] Iter 8: observed MAE=0.203788 rank=8\n",
      "[SoftImpute] Iter 9: observed MAE=0.202717 rank=8\n",
      "[SoftImpute] Iter 10: observed MAE=0.200466 rank=7\n",
      "[SoftImpute] Iter 11: observed MAE=0.197368 rank=7\n",
      "[SoftImpute] Iter 12: observed MAE=0.195333 rank=7\n",
      "[SoftImpute] Iter 13: observed MAE=0.193817 rank=7\n",
      "[SoftImpute] Iter 14: observed MAE=0.192926 rank=7\n",
      "[SoftImpute] Iter 15: observed MAE=0.192307 rank=7\n",
      "[SoftImpute] Iter 16: observed MAE=0.191821 rank=7\n",
      "[SoftImpute] Iter 17: observed MAE=0.191419 rank=7\n",
      "[SoftImpute] Iter 18: observed MAE=0.191064 rank=7\n",
      "[SoftImpute] Iter 19: observed MAE=0.190727 rank=7\n",
      "[SoftImpute] Iter 20: observed MAE=0.190390 rank=7\n",
      "[SoftImpute] Iter 21: observed MAE=0.190056 rank=7\n",
      "[SoftImpute] Iter 22: observed MAE=0.189727 rank=7\n",
      "[SoftImpute] Iter 23: observed MAE=0.189367 rank=7\n",
      "[SoftImpute] Iter 24: observed MAE=0.188969 rank=7\n",
      "[SoftImpute] Iter 25: observed MAE=0.188533 rank=7\n",
      "[SoftImpute] Iter 26: observed MAE=0.188054 rank=7\n",
      "[SoftImpute] Iter 27: observed MAE=0.187532 rank=7\n",
      "[SoftImpute] Iter 28: observed MAE=0.186966 rank=7\n",
      "[SoftImpute] Iter 29: observed MAE=0.186400 rank=6\n",
      "[SoftImpute] Iter 30: observed MAE=0.183410 rank=6\n",
      "[SoftImpute] Iter 31: observed MAE=0.181847 rank=6\n",
      "[SoftImpute] Iter 32: observed MAE=0.180847 rank=6\n",
      "[SoftImpute] Iter 33: observed MAE=0.180159 rank=6\n",
      "[SoftImpute] Iter 34: observed MAE=0.179652 rank=6\n",
      "[SoftImpute] Iter 35: observed MAE=0.179253 rank=6\n",
      "[SoftImpute] Iter 36: observed MAE=0.178920 rank=6\n",
      "[SoftImpute] Iter 37: observed MAE=0.178668 rank=6\n",
      "[SoftImpute] Iter 38: observed MAE=0.178540 rank=6\n",
      "[SoftImpute] Iter 39: observed MAE=0.178407 rank=6\n",
      "[SoftImpute] Iter 40: observed MAE=0.178263 rank=6\n",
      "[SoftImpute] Iter 41: observed MAE=0.178103 rank=6\n",
      "[SoftImpute] Iter 42: observed MAE=0.177922 rank=6\n",
      "[SoftImpute] Iter 43: observed MAE=0.176132 rank=5\n",
      "[SoftImpute] Iter 44: observed MAE=0.174887 rank=5\n",
      "[SoftImpute] Iter 45: observed MAE=0.174080 rank=5\n",
      "[SoftImpute] Iter 46: observed MAE=0.173506 rank=5\n",
      "[SoftImpute] Iter 47: observed MAE=0.173075 rank=5\n",
      "[SoftImpute] Iter 48: observed MAE=0.172738 rank=5\n",
      "[SoftImpute] Iter 49: observed MAE=0.172464 rank=5\n",
      "[SoftImpute] Iter 50: observed MAE=0.172235 rank=5\n",
      "[SoftImpute] Iter 51: observed MAE=0.172037 rank=5\n",
      "[SoftImpute] Iter 52: observed MAE=0.171861 rank=5\n",
      "[SoftImpute] Iter 53: observed MAE=0.171702 rank=5\n",
      "[SoftImpute] Iter 54: observed MAE=0.171554 rank=5\n",
      "[SoftImpute] Iter 55: observed MAE=0.171415 rank=5\n",
      "[SoftImpute] Iter 56: observed MAE=0.171283 rank=5\n",
      "[SoftImpute] Iter 57: observed MAE=0.171174 rank=5\n",
      "[SoftImpute] Iter 58: observed MAE=0.171098 rank=5\n",
      "[SoftImpute] Iter 59: observed MAE=0.171022 rank=5\n",
      "[SoftImpute] Iter 60: observed MAE=0.170945 rank=5\n",
      "[SoftImpute] Iter 61: observed MAE=0.170869 rank=5\n",
      "[SoftImpute] Iter 62: observed MAE=0.170793 rank=5\n",
      "[SoftImpute] Iter 63: observed MAE=0.170717 rank=5\n",
      "[SoftImpute] Iter 64: observed MAE=0.170640 rank=5\n",
      "[SoftImpute] Iter 65: observed MAE=0.170564 rank=5\n",
      "[SoftImpute] Iter 66: observed MAE=0.170488 rank=5\n",
      "[SoftImpute] Iter 67: observed MAE=0.170411 rank=5\n",
      "[SoftImpute] Iter 68: observed MAE=0.170336 rank=5\n",
      "[SoftImpute] Iter 69: observed MAE=0.170260 rank=5\n",
      "[SoftImpute] Iter 70: observed MAE=0.170184 rank=5\n",
      "[SoftImpute] Iter 71: observed MAE=0.170110 rank=5\n",
      "[SoftImpute] Iter 72: observed MAE=0.170035 rank=5\n",
      "[SoftImpute] Iter 73: observed MAE=0.169961 rank=5\n",
      "[SoftImpute] Iter 74: observed MAE=0.169887 rank=5\n",
      "[SoftImpute] Iter 75: observed MAE=0.169814 rank=5\n",
      "[SoftImpute] Iter 76: observed MAE=0.169742 rank=5\n",
      "[SoftImpute] Iter 77: observed MAE=0.169671 rank=5\n",
      "[SoftImpute] Iter 78: observed MAE=0.169600 rank=5\n",
      "[SoftImpute] Iter 79: observed MAE=0.169529 rank=5\n",
      "[SoftImpute] Iter 80: observed MAE=0.169460 rank=5\n",
      "[SoftImpute] Iter 81: observed MAE=0.169391 rank=5\n",
      "[SoftImpute] Iter 82: observed MAE=0.169324 rank=5\n",
      "[SoftImpute] Iter 83: observed MAE=0.169257 rank=5\n",
      "[SoftImpute] Iter 84: observed MAE=0.169191 rank=5\n",
      "[SoftImpute] Iter 85: observed MAE=0.169125 rank=5\n",
      "[SoftImpute] Iter 86: observed MAE=0.169061 rank=5\n",
      "[SoftImpute] Iter 87: observed MAE=0.168998 rank=5\n",
      "[SoftImpute] Iter 88: observed MAE=0.168935 rank=5\n",
      "[SoftImpute] Iter 89: observed MAE=0.168879 rank=5\n",
      "[SoftImpute] Iter 90: observed MAE=0.168851 rank=5\n",
      "[SoftImpute] Iter 91: observed MAE=0.168824 rank=5\n",
      "[SoftImpute] Iter 92: observed MAE=0.168796 rank=5\n",
      "[SoftImpute] Iter 93: observed MAE=0.168768 rank=5\n",
      "[SoftImpute] Iter 94: observed MAE=0.168741 rank=5\n",
      "[SoftImpute] Iter 95: observed MAE=0.168714 rank=5\n",
      "[SoftImpute] Iter 96: observed MAE=0.168686 rank=5\n",
      "[SoftImpute] Iter 97: observed MAE=0.168659 rank=5\n",
      "[SoftImpute] Iter 98: observed MAE=0.168632 rank=5\n",
      "[SoftImpute] Iter 99: observed MAE=0.168604 rank=5\n",
      "[SoftImpute] Iter 100: observed MAE=0.168577 rank=5\n",
      "[SoftImpute] Stopped after iteration 100 for lambda=0.541324\n"
     ]
    }
   ],
   "source": [
    "Y = f.solve(X, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50119461,  2.28824098,  5.        ,  7.        ,  3.83233896,\n",
       "         8.        ,  2.89075151,  2.91119669,  3.10229705,  0.68266838],\n",
       "       [ 2.14450166,  0.59666375,  2.40521439,  1.77993299,  1.98527851,\n",
       "         7.        ,  4.        ,  3.43476155,  3.02866525, -0.01429112],\n",
       "       [ 8.        ,  7.        ,  5.36452994,  0.        ,  5.7049496 ,\n",
       "         3.19112464,  6.        ,  7.        ,  2.45331449,  0.6829472 ],\n",
       "       [ 2.88087834,  1.85207091,  1.5645849 ,  0.18130348,  1.        ,\n",
       "         3.21279626,  4.        ,  2.7800013 ,  1.52822843,  0.        ],\n",
       "       [ 0.        ,  1.37074117,  2.2227966 ,  3.        ,  1.63898688,\n",
       "         2.18482037,  0.69546994,  0.87293966,  1.        ,  0.40289921],\n",
       "       [ 3.94997061,  1.75169969,  5.        ,  1.        ,  4.        ,\n",
       "         9.        ,  5.13647342,  6.        ,  5.        ,  0.25012523],\n",
       "       [ 4.11918172,  5.57549625,  6.        ,  3.        ,  6.        ,\n",
       "         3.45305023,  3.20168253,  5.        ,  2.29493623,  0.97644543],\n",
       "       [ 5.        ,  8.        ,  7.32434907,  4.        ,  8.        ,\n",
       "         2.09097482,  3.00396126,  5.2812263 ,  1.82097631,  1.39309739],\n",
       "       [ 3.44608386,  9.        ,  9.        ,  5.        ,  6.30628903,\n",
       "         0.        ,  2.        ,  3.85597878,  1.09369261,  2.        ],\n",
       "       [ 3.81378511,  8.        ,  5.40218524,  2.52511493,  4.        ,\n",
       "        -1.3424421 ,  2.28414616,  2.97926586,  0.        ,  1.25096696]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50119461,  2.28824098,  5.        ,  7.        ,  3.83233896,\n",
       "         8.        ,  2.89075151,  2.91119669,  3.10229705,  0.68266838],\n",
       "       [ 2.14450166,  0.59666375,  2.40521439,  1.77993299,  1.98527851,\n",
       "         7.        ,  4.        ,  3.43476155,  3.02866525, -0.01429112],\n",
       "       [ 8.        ,  7.        ,  5.36452994,  0.        ,  5.7049496 ,\n",
       "         3.19112464,  6.        ,  7.        ,  2.45331449,  0.6829472 ],\n",
       "       [ 2.88087834,  1.85207091,  1.5645849 ,  0.18130348,  1.        ,\n",
       "         3.21279626,  4.        ,  2.7800013 ,  1.52822843,  0.        ],\n",
       "       [ 0.        ,  1.37074117,  2.2227966 ,  3.        ,  1.63898688,\n",
       "         2.18482037,  0.69546994,  0.87293966,  1.        ,  0.40289921],\n",
       "       [ 3.94997061,  1.75169969,  5.        ,  1.        ,  4.        ,\n",
       "         9.        ,  5.13647342,  6.        ,  5.        ,  0.25012523],\n",
       "       [ 4.11918172,  5.57549625,  6.        ,  3.        ,  6.        ,\n",
       "         3.45305023,  3.20168253,  5.        ,  2.29493623,  0.97644543],\n",
       "       [ 5.        ,  8.        ,  7.32434907,  4.        ,  8.        ,\n",
       "         2.09097482,  3.00396126,  5.2812263 ,  1.82097631,  1.39309739],\n",
       "       [ 3.44608386,  9.        ,  9.        ,  5.        ,  6.30628903,\n",
       "         0.        ,  2.        ,  3.85597878,  1.09369261,  2.        ],\n",
       "       [ 3.81378511,  8.        ,  5.40218524,  2.52511493,  4.        ,\n",
       "        -1.3424421 ,  2.28414616,  2.97926586,  0.        ,  1.25096696]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T01:40:20.237401Z",
     "start_time": "2020-09-19T01:40:20.215108Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T01:40:21.997941Z",
     "start_time": "2020-09-19T01:40:21.976314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  7,  4,  3,  2,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T01:40:22.730399Z",
     "start_time": "2020-09-19T01:40:22.709167Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T01:41:27.055837Z",
     "start_time": "2020-09-19T01:41:27.031422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([10, 7, 4, 3, 2, 1])\n",
    "np.where(np.cumsum(a) > 80*np.cumsum(a)[-1]/100)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T01:39:33.809576Z",
     "start_time": "2020-09-19T01:39:33.786025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
