{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state transition bias and reward function for a cart pole system\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdim = 4\n",
    "adim = 1\n",
    "ssize = 10\n",
    "asize = 100\n",
    "srange = np.array([-np.pi/4, np.pi/4, -3, 3, -2.4, 2.4, -3.5, 3.5])\n",
    "arange = np.array([-10, 10])\n",
    "\n",
    "g = 9.8\n",
    "l =0.5\n",
    "M = 1\n",
    "m = 0.1\n",
    "tau = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(c, d):\n",
    "    return [list(np.ndindex(*d))[i] for i in c]\n",
    "\n",
    "\n",
    "def foldParallel(c, d):\n",
    "    p = np.array([np.prod(d[i + 1 :]) for i, _ in enumerate(d)])\n",
    "    return np.sum(c * p, -1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_spaces(srange, arange, ssize, asize, sdim, adim):\n",
    "    srange = np.reshape(srange, (sdim, -1))\n",
    "    arange = np.reshape(arange, (adim, -1))\n",
    "\n",
    "    # Dicretization of [a, b] will include a, but exlude b when range if not multiple of step-size\n",
    "    statespace = np.meshgrid(*[np.linspace(a, b, ssize) for (a, b) in srange])\n",
    "    actionspace = np.meshgrid(*[np.linspace(a, b, asize) for (a, b) in arange])\n",
    "\n",
    "    return statespace, actionspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "statespace, actionspace = build_spaces(srange, arange, ssize, asize, sdim, adim)\n",
    "# print(statespace)\n",
    "# cs = np.random.randint(0, statespace[0].size, samples) # current states\n",
    "# ca = np.random.randint(0, actionspace[0].size, samples) # current states\n",
    "\n",
    "# states = np.array(unfold(cs, statespace[0].shape))\n",
    "# states = np.array([s[states] for s in statespace])\n",
    "# actions = np.array(unfold(ca, actionspace[0].shape))\n",
    "# states = np.array([a[actions] for a in actionspace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_action_bias_reward(statespace, actionspace, args):\n",
    "    \"\"\"\n",
    "    nstates: total number of states\n",
    "    nactions: total number of actions\n",
    "    \"\"\"\n",
    "    assert len(srange.shape) == 1\n",
    "    #assert args.adim == 1\n",
    "    \n",
    "    coords = np.array(statespace).reshape(sdim, -1).transpose()\n",
    "    coorda = actionspace[0]\n",
    "    c = np.array(list(np.ndindex(len(coords), len(coorda))))\n",
    "    cartcoord = np.c_[coords[c[:, 0]], coorda[c[:, 1]]]\n",
    "    \n",
    "    angaccel = (g * np.sin(cartcoord[:,0]) - (cartcoord[:, -1] + m * l * cartcoord[:,1] ** 2 * np.sin(cartcoord[:,0])) * np.cos(cartcoord[:,0]) / (M + m)) / (l * (4 / 3 - (m * np.cos(cartcoord[:,0]) ** 2) / (M+m)))\n",
    "    linaccel = (cartcoord[:, -1] + m * l *(cartcoord[:,0] ** 2 * np.sin(cartcoord[:,0]) - angaccel * np.cos(cartcoord[:,0]))) / (M + m)\n",
    "    \n",
    "    bias = np.c_[tau*cartcoord[:,1], tau*angaccel, tau*cartcoord[:,2], tau*linaccel]\n",
    "    \n",
    "    reward = np.reshape(np.cos(cartcoord[:, 0]) ** 4, (len(coords), len(coorda), -1))\n",
    "    \n",
    "    # convert to discrete co-ordinates\n",
    "    statesrange = np.reshape(srange, (sdim, -1))\n",
    "    sr = np.array([np.linspace(a, b, ssize) for (a, b) in statesrange]) #use args.ssize\n",
    "    bias = np.array(\n",
    "        [\n",
    "            np.argmin(np.abs(bias[:, i : i + 1] - sr[i : i + 1]), -1)\n",
    "            for i in range(sdim)\n",
    "        ]\n",
    "    ).T\n",
    "    bias = np.reshape(bias, (len(coords), len(coorda), -1))\n",
    "    return bias, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, R = get_state_action_bias_reward(statespace, actionspace, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-31836aeaab22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'B' is not defined"
     ]
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.45025452, 0.67468778, 0.8705127 , 0.98486545])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853981633974483"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "momentum tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sdim = 3\n",
    "params = torch.ones(2, sdim)\n",
    "print(\"params\", params)\n",
    "\n",
    "momentum = torch.ones(2, sdim)\n",
    "print(\"momentum\",momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.ones(sdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.2568)\n"
     ]
    }
   ],
   "source": [
    "def log_prob(omega):\n",
    "    \"\"\"\n",
    "        Sampling from a trucated Gaussian distribution\n",
    "    \"\"\"\n",
    "#     mean = torch.cat([torch.zeros(1, sdim),torch.ones(1, sdim)],dim=0)\n",
    "#     cov = torch.cat([torch.eye(sdim).view(1,sdim,sdim),2*torch.eye(sdim).view(1,sdim,sdim)],dim=0)\\\n",
    "    mean = torch.zeros(sdim)\n",
    "    cov = torch.eye(sdim)\n",
    "    normal_log = torch.distributions.MultivariateNormal(mean, cov).log_prob(omega)\n",
    "    \n",
    "    return normal_log\n",
    "\n",
    "print(log_prob(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-3ef955b8b6e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollect_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-122-3ef955b8b6e0>\u001b[0m in \u001b[0;36mcollect_gradients\u001b[0;34m(log_prob, params)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "def collect_gradients(log_prob, params):\n",
    "    if isinstance(log_prob, tuple):\n",
    "        log_prob[0].backward()\n",
    "        params_list = list(log_prob[1])\n",
    "        params = torch.cat([p.flatten() for p in params_list])\n",
    "        params.grad = torch.cat([p.grad.flatten() for p in params_list])\n",
    "    else:\n",
    "        params.grad = torch.autograd.grad(log_prob, params)[0]\n",
    "    return params\n",
    "\n",
    "log_prob = log_prob(params)\n",
    "print(collect_gradients(log_prob, params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7161,  0.4260,  2.3050],\n",
      "        [ 0.4742, -1.0164,  0.8682]])\n"
     ]
    }
   ],
   "source": [
    "def gibbs(\n",
    "    params,\n",
    "    mass=None,\n",
    "):\n",
    "\n",
    "    if mass is None:\n",
    "        dist = torch.distributions.Normal(\n",
    "            torch.zeros_like(params), torch.ones_like(params)\n",
    "        )\n",
    "    else:\n",
    "        if len(mass.shape) == 2:\n",
    "            dist = torch.distributions.MultivariateNormal(\n",
    "                torch.zeros_like(params), mass\n",
    "            )\n",
    "        elif len(mass.shape) == 1:\n",
    "            dist = torch.distributions.Normal(torch.zeros_like(params), mass)\n",
    "    return dist.sample()\n",
    "\n",
    "print(gibbs(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.7568, 5.2965])\n"
     ]
    }
   ],
   "source": [
    "def hamiltonian(\n",
    "    params,\n",
    "    momentum,\n",
    "    log_prob_func,\n",
    "    inv_mass=None,\n",
    "):\n",
    "\n",
    "    log_prob = log_prob_func(params)\n",
    "    potential = -log_prob\n",
    "    \n",
    "    if inv_mass is None:\n",
    "        kinetic = 0.5 * torch.sum(momentum ** 2, dim = -1)\n",
    "        \n",
    "    else:\n",
    "        if len(inv_mass.shape) == 2:\n",
    "            # Have not checked for parallel\n",
    "            kinetic = 0.5 * torch.matmul(\n",
    "                momentum.view(1, -1), torch.matmul(inv_mass, momentum.view(-1, 1))\n",
    "            ).view(-1)\n",
    "        else:\n",
    "            kinetic = 0.5 * inv_mass * torch.sum(momentum ** 2, dim = -1)\n",
    "    hamiltonian = potential + kinetic\n",
    "\n",
    "    return hamiltonian\n",
    "\n",
    "print(hamiltonian(params, momentum, log_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 3],[2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor([2, 3]) **2 ,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.tensor([2, 3]),torch.tensor([2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
